{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook presents the whole data cleaning process, which consists in extracting new tables and relations, as well as cleaning the existing files from dirty tuples and values.\n",
    "\n",
    "The new clean data files are saved in the `.csv` format, and will be used to load data to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "We first import all the `.csv` files into `pandas` DataFrames.\n",
    "\n",
    "_Note_: some lines are ill-formed, we choose to ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "b'Skipping line 6010: expected 16 fields, saw 29\\nSkipping line 14907: expected 16 fields, saw 29\\n'\n",
      "b'Skipping line 142947: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 379178: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 411105: expected 16 fields, saw 18\\n'\n",
      "b'Skipping line 532885: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 625092: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 743624: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 786680: expected 16 fields, saw 27\\n'\n",
      "b'Skipping line 892034: expected 16 fields, saw 29\\n'\n",
      "b'Skipping line 1157212: expected 16 fields, saw 29\\nSkipping line 1157657: expected 16 fields, saw 29\\n'\n",
      "b'Skipping line 1265876: expected 16 fields, saw 29\\n'\n",
      "b'Skipping line 1460021: expected 16 fields, saw 22\\n'\n",
      "b'Skipping line 1591431: expected 16 fields, saw 29\\n'\n",
      "b'Skipping line 1615982: expected 16 fields, saw 29\\nSkipping line 1623916: expected 16 fields, saw 23\\n'\n",
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Root of the data files\n",
    "PATH = os.path.join('..', 'data', 'original')\n",
    "\n",
    "# Dic: name -> dataframe\n",
    "dataframes = {}\n",
    "\n",
    "# Get all the original files\n",
    "for file in os.listdir(PATH):\n",
    "    name = file.split('.')[0]\n",
    "    # Note: some lines are ill-formed, we ignore them\n",
    "    dataframes[name] = pd.read_csv(os.path.join(PATH, file), error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes table\n",
    "\n",
    "This part aims to extract the notes from each table containing a `notes` attributes. Notes are loaded in a new table, and replaced by foreign keys in the original tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first concatenate all the notes from all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    The company was founded in 1865 by a bookselle...\n",
       "2    The Graphic Office 190 Strand London W.CAddres...\n",
       "3    Star published a line of coloring books in com...\n",
       "4    Cupples & Leon was founded in 1902 by Victor I...\n",
       "5    Intended to be used for books that contain no ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = pd.Series()\n",
    "for _, df in dataframes.items():\n",
    "    if 'notes' in df.columns: \n",
    "        note = df['notes'].dropna()\n",
    "        notes = notes.append(note, ignore_index=True)\n",
    "\n",
    "# Keep unique notes\n",
    "notes = notes.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "# Shift to start with ID 1\n",
    "notes.index = notes.index + 1\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new notes dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The company was founded in 1865 by a bookselle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Graphic Office 190 Strand London W.CAddres...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Star published a line of coloring books in com...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cupples &amp; Leon was founded in 1902 by Victor I...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intended to be used for books that contain no ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               notes  id\n",
       "1  The company was founded in 1865 by a bookselle...   1\n",
       "2  The Graphic Office 190 Strand London W.CAddres...   2\n",
       "3  Star published a line of coloring books in com...   3\n",
       "4  Cupples & Leon was founded in 1902 by Victor I...   4\n",
       "5  Intended to be used for books that contain no ...   5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form a DataFrame from the note Series\n",
    "notes_df = notes.to_frame()\n",
    "notes_df.columns = ['notes']\n",
    "notes_df['id'] = notes_df.index\n",
    "\n",
    "dataframes['notes'] = notes_df[['id', 'notes']]\n",
    "notes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the notes by the IDs in the original tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Series from notes to uniqueID\n",
    "notes_mapper = pd.Series(notes.index, index=notes)\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # Skip the notes dataframe obviously\n",
    "    if name == 'notes':\n",
    "        continue\n",
    "    \n",
    "    if 'notes' in df.columns:\n",
    "        # Map notes to their IDs\n",
    "        df['notes'] = df['notes'].map(notes_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First/Last issue Relation\n",
    "\n",
    "We noticed that there is a cyclic dependency between the tables _Issues_ and _Series_, since issues belong to a serie, and series have a first and last issue. It's generally a bad idea (and impossible practically) to create such cyclic relations between tables. So we decide to create a new relation *First_last_issue* to link series with their first and last issue, and remove the reference to _Issues_ in _Series_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie_id</th>\n",
       "      <th>first_issue_id</th>\n",
       "      <th>last_issue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serie_id  first_issue_id  last_issue_id\n",
       "0         1             1.0            1.0\n",
       "1         2             2.0            2.0\n",
       "2         3             3.0            3.0\n",
       "3         4             6.0            6.0\n",
       "4         5             4.0            4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relation\n",
    "first_last_issue = dataframes['series'][['id', 'first_issue_id', 'last_issue_id']]\n",
    "\n",
    "# Rename the columns\n",
    "first_last_issue.columns = ['serie_id', 'first_issue_id', 'last_issue_id']\n",
    "\n",
    "# Remove rows if first_issue_id and last_issue_id are both NULL\n",
    "first_last_issue = first_last_issue.dropna(subset=['first_issue_id', 'last_issue_id'], how='all')\n",
    "\n",
    "# Save the new relation\n",
    "dataframes['first_last_issue'] = first_last_issue\n",
    "\n",
    "first_last_issue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now drop the *first_issue_id* and *last_issue_id* coumns of _Series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['series'] = dataframes['series'].drop(['first_issue_id', 'last_issue_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artists table\n",
    "\n",
    "We first scan through all the different categories of artists , clean the data and then store all artist in one single table as described in our ER diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                   Gustave Doré\n",
       "2    Wilhelm Busch; Harry Rogers\n",
       "3         The Donaldson Brothers\n",
       "4                  Wilhelm Busch\n",
       "5                  Richard Doyle\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make table to store the list of all artists\n",
    "all_artists = pd.Series()\n",
    "# Dictionnary to store all artists of one category\n",
    "artists = {}\n",
    "categories = ['script','pencils','inks','colors','letters']\n",
    "story_df = dataframes['story']\n",
    "\n",
    "for category in categories:\n",
    "    #remove all data in () and in [], removes trailing white space and set empty cells to nan\n",
    "    story_df[category] = story_df[category].str.replace(r\"(\\(.*\\))|(\\[.*\\])|\\?\",\"\").str.strip('; ').replace('',np.nan)\n",
    "\n",
    "    artists[category] = story_df[category]\n",
    "    # Set the index of artists to the corresponding stoy_id\n",
    "    artists[category].index = story_df['id']\n",
    "    #remove nan\n",
    "    artists[category] = artists[category].dropna()\n",
    "    #add artits to the global table\n",
    "    all_artists = all_artists.append(artists[category],ignore_index=True)\n",
    "    \n",
    "# Keep unique artists\n",
    "all_artists = all_artists.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "# Shift to start with ID 1\n",
    "all_artists.index = all_artists.index + 1\n",
    "all_artists.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we correctly index the different category of artists table with the correct story index and the correct artists index. We also save these artists in the dataframe where we store all our tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gustave Doré</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wilhelm Busch; Harry Rogers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Donaldson Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wilhelm Busch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richard Doyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "1                 Gustave Doré\n",
       "2  Wilhelm Busch; Harry Rogers\n",
       "3       The Donaldson Brothers\n",
       "4                Wilhelm Busch\n",
       "5                Richard Doyle"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series from artists to uniqueID\n",
    "artist_mapper = pd.Series(all_artists.index, index=all_artists)\n",
    "\n",
    "for category in categories:\n",
    "   \n",
    "    artists[category] = artists[category].to_frame() \n",
    "    artists[category]['story_id'] = artists[category].index\n",
    "    artists[category].columns = ['artist_id','story_id']\n",
    "    artists[category]['artist_id'] = artists[category]['artist_id'].map(artist_mapper)\n",
    "    \n",
    "    dataframes[category] = artists[category]\n",
    "    \n",
    "    \n",
    "dataframes['artists'] = all_artists.to_frame()\n",
    "dataframes['artists'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    story_df = story_df.drop(category,axis = 1)\n",
    "dataframes['story']= story_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual files cleaning\n",
    "\n",
    "This part aims to clean each `.csv` file individually in order to remove dirty rows and clear values that need some special treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Country\n",
    "\n",
    "By browsing the country data, we see that one row is not valid, with ID 248. We see in the cell below that for `publisher`, for example, no row references this ID, which is with high probably pure dirty data, we can safely remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publisher with country_id 248: 0.\n",
      "NaN values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "code    0\n",
       "name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub = dataframes['publisher']\n",
    "print('Number of publisher with country_id 248: {}.'.format(len(pub[pub['country_id'] == 248])))\n",
    "\n",
    "# Look for NaN values\n",
    "print('NaN values: ')\n",
    "df = dataframes['country']\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the desired row\n",
    "dataframes['country'] = df[df['id'] != 248]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story Reprint\n",
    "\n",
    "The story reprint table needs to be full, as we don't accept _NULL_ foreign keys in this case. We see in the cell below that there are no empty cells in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "origin_id    0\n",
       "target_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['story_reprint'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story Type\n",
    "\n",
    "By looking at the story types we see that the third row is problematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                             3\n",
       "name    (backcovers) *do not use* / *please fix*\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataframes['story_type']\n",
    "df.ix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if any story contains a reference to this row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stories referencing ID 3: 0.\n"
     ]
    }
   ],
   "source": [
    "stories = dataframes['story']\n",
    "print('Number of stories referencing ID 3: {}.'.format(len(stories[stories['type_id'] == 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['story_type'] = df[df['id'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language\n",
    "\n",
    "Looking at the language file, all the rows are clean and it's safe to keep them as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "code    0\n",
       "name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['language'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brang group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "name               0\n",
       "year_began      2938\n",
       "year_ended      3857\n",
       "notes           4615\n",
       "url             4701\n",
       "publisher_id       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['brand_group'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the essential attributes don't have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marvel           17\n",
       "DC               10\n",
       "Dargaud           8\n",
       "A                 7\n",
       "Panini Comics     6\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['brand_group']['name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we see that there are quite a lot of duplicates in the names. But if we look at the cell below, for the same names, we have each time different *publisher_id*s, so it makes sense to keep these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2105,  613, 3434,   78, 4720, 3174, 4437,  592, 3029, 8492, 7151,\n",
       "       2195, 5905, 1798, 1977, 3655, 6917])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['brand_group'][dataframes['brand_group']['name'] == 'Marvel']['publisher_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Publication types\n",
    "Obviously this table is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>magazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name\n",
       "0   1      book\n",
       "1   2  magazine\n",
       "2   3     album"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['series_publication_type'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Reprint\n",
    "\n",
    "We make sure there is no null rows in the reprint table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "origin_issue_id    0\n",
       "target_issue_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['issue_reprint'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicia Publisher\n",
    "\n",
    "For this table we need to make sure the *publisher_id* attribute is not null, which is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "name               0\n",
       "publisher_id       0\n",
       "country_id         0\n",
       "year_began      2612\n",
       "year_ended      3563\n",
       "is_surrogate       0\n",
       "notes           4282\n",
       "url             4711\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['indicia_publisher'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files\n",
    "\n",
    "We can now save our clean and new tables, ready for database loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nOUTPUT_PATH = os.path.join('..', 'data', 'clean')\\nfor name, df in dataframes.items():\\n    df.to_csv(name.title() + '.csv', index=False, float_format='%.0f')\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "OUTPUT_PATH = os.path.join('..', 'data', 'clean')\n",
    "for name, df in dataframes.items():\n",
    "    df.to_csv(name.title() + '.csv', index=False, float_format='%.0f')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
