{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook presents the whole data cleaning process, which consists in extracting new tables and relations, as well as cleaning the existing files from dirty tuples and values.\n",
    "\n",
    "The new clean data files are saved in the `.csv` format, and will be used to load data to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "We first import all the `.csv` files into `pandas` DataFrames.\n",
    "\n",
    "_Note_: some lines are ill-formed, we choose to ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Root of the data files\n",
    "PATH = os.path.join('..', 'data', 'original')\n",
    "\n",
    "# Dic: name -> dataframe\n",
    "dataframes = {}\n",
    "\n",
    "# Get all the original files\n",
    "for file in os.listdir(PATH):\n",
    "    # Skip hidden files\n",
    "    if (file.startswith('.')):\n",
    "        continue\n",
    "        \n",
    "    name = file.split('.')[0]\n",
    "    # Note: some lines are ill-formed, we ignore them\n",
    "    dataframes[name] = pd.read_csv(os.path.join(PATH, file), encoding='utf-8', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just remove here all stories that have everything null appart from _type-id issue-id_ and _id_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['story'] = dataframes['story'].dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes table\n",
    "\n",
    "This part aims to extract the notes from each table containing a `notes` attributes. Notes are loaded in a new table, and replaced by foreign keys in the original tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first concatenate all the notes from all the dataframes. And create the new note dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Used for the MLJ superheroes that DC licensed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>An imprint of HarperCollins Publishers; URL li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Lancé en 2008 le label Fusion Comics était com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a highly-stylized \"A\" with the crossbar formed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Letter B is larger than rest of text.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              notes\n",
       "1   1  Used for the MLJ superheroes that DC licensed ...\n",
       "2   2  An imprint of HarperCollins Publishers; URL li...\n",
       "3   3  Lancé en 2008 le label Fusion Comics était com...\n",
       "4   4  a highly-stylized \"A\" with the crossbar formed...\n",
       "5   5              Letter B is larger than rest of text."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = pd.Series()\n",
    "\n",
    "# Get all the notes from all the dataframes containing notes\n",
    "for _, df in dataframes.items():\n",
    "    if 'notes' in df.columns: \n",
    "        notes = notes.append(df['notes'].dropna(), ignore_index=True)\n",
    "    \n",
    "    if 'reprint_notes' in df.columns:\n",
    "        notes = notes.append(df['reprint_notes'].dropna(), ignore_index=True)\n",
    "\n",
    "notes_df = utils.extract_table(notes, 'notes')\n",
    "dataframes['notes'] = notes_df\n",
    "notes_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the notes by the IDs in the original tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in dataframes.items():\n",
    "    # Skip the notes dataframe obviously\n",
    "    if name == 'notes':\n",
    "        continue\n",
    "    \n",
    "    if 'notes' in df.columns:\n",
    "        # Map notes to their IDs\n",
    "        df['notes_id'] = utils.map_column(df['notes'], dataframes['notes'], 'id', 'notes')\n",
    "        df.drop('notes', axis=1, inplace=True)\n",
    "        \n",
    "    if 'reprint_notes' in df.columns:\n",
    "        df['reprint_notes_id'] = utils.map_column(df['reprint_notes'], dataframes['notes'], 'id', 'notes')\n",
    "        df.drop('reprint_notes', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1    86501.0\n",
       "2    86502.0\n",
       "3    86502.0\n",
       "4        NaN\n",
       "Name: notes_id, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['story']['notes_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "5    377020.0\n",
       "6         NaN\n",
       "7    377021.0\n",
       "8    377021.0\n",
       "9         NaN\n",
       "Name: reprint_notes_id, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['story']['reprint_notes_id'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First/Last issue Relation\n",
    "\n",
    "We noticed that there is a cyclic dependency between the tables _Issues_ and _Series_, since issues belong to a serie, and series have a first and last issue. It's generally a bad idea (and impossible practically) to create such cyclic relations between tables. So we decide to create a new relation *First_last_issue* to link series with their first and last issue, and remove the reference to _Issues_ in _Series_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie_id</th>\n",
       "      <th>first_issue_id</th>\n",
       "      <th>last_issue_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serie_id  first_issue_id  last_issue_id\n",
       "0         1             1.0            1.0\n",
       "1         2             2.0            2.0\n",
       "2         3             3.0            3.0\n",
       "3         4             6.0            6.0\n",
       "4         5             4.0            4.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relation\n",
    "first_last_issue = dataframes['series'][['id', 'first_issue_id', 'last_issue_id']]\n",
    "\n",
    "# Rename the columns\n",
    "first_last_issue.columns = ['serie_id', 'first_issue_id', 'last_issue_id']\n",
    "\n",
    "# Remove rows if first_issue_id and last_issue_id are both NULL\n",
    "first_last_issue = first_last_issue.dropna(subset=['first_issue_id', 'last_issue_id'], how='all')\n",
    "\n",
    "# Save the new relation\n",
    "dataframes['first_last_issue'] = first_last_issue\n",
    "\n",
    "first_last_issue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now drop the *first_issue_id* and *last_issue_id* columns of _Series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['series'] = dataframes['series'].drop(['first_issue_id', 'last_issue_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artists table\n",
    "\n",
    "We first scan through all the different categories of artists , clean the data and then store all artist in one single table as described in our ER diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table to store the list of all artists\n",
    "all_artists = pd.Series()\n",
    "# Dictionnary to store all artists of one category\n",
    "artists = {}\n",
    "categories = ['script', 'pencils', 'inks', 'colors', 'letters']\n",
    "\n",
    "for category in categories:\n",
    "    # Unpack the artists lists so we have all artists for every story\n",
    "    unpacked = utils.unpack_column(dataframes['story'], 'id', category)\n",
    "    \n",
    "    # Clean the unpacked elements \n",
    "    unpacked[category] = utils.clean_column(unpacked[category])\n",
    "    \n",
    "    # We have now our relation with story IDs and artists names\n",
    "    artists[category] = unpacked.dropna(how='any')\n",
    "    \n",
    "    # Add artists to the global artist list\n",
    "    all_artists = all_artists.append(artists[category][category], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract our new artists table from the whole list of artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gustave Doré</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Rogers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilhelm Busch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Donaldson Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Richard Doyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    name\n",
       "1   1            Gustave Doré\n",
       "2   2            Harry Rogers\n",
       "3   3           Wilhelm Busch\n",
       "4   4  The Donaldson Brothers\n",
       "5   5           Richard Doyle"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['artists'] = utils.extract_table(all_artists, 'name')\n",
    "dataframes['artists'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each relation of artist, we map the names to the IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    relation = artists[category]\n",
    "    relation.columns = ['story_id', 'artist_id']\n",
    "    relation['artist_id'] = utils.map_column(relation['artist_id'], dataframes['artists'], 'id', 'name')\n",
    "    dataframes[category] = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    story_id  artist_id\n",
       "7       13.0          1\n",
       "8       14.0          1\n",
       "9       15.0          1\n",
       "10      16.0          1\n",
       "11      17.0          1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['script'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now drop the different artists columns from the original Story dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['story'] = dataframes['story'].drop(categories, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters table\n",
    "\n",
    "We are now interested in extracting the characters and building the corresponding relations between _Stories_ and _Characters_. We consider the _characters_ and _feature_ attributes of _Stories_ to be characters, but we build different relationships to keep the original meaning.\n",
    "\n",
    "Note that some cells contains multiples values, so we need to unpack them, as we did for _Artists_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_characters = pd.Series()\n",
    "char_types = ['feature', 'characters']\n",
    "char_relations = {}\n",
    "\n",
    "for c_type in char_types:\n",
    "    # Extract relation and unpack the lists\n",
    "    unpacked = utils.unpack_column(dataframes['story'][['id', c_type]], 'id', c_type)\n",
    "    \n",
    "    # Clean values\n",
    "    unpacked[c_type] = utils.clean_column(unpacked[c_type])\n",
    "    unpacked = unpacked.dropna(how='any')\n",
    "    \n",
    "    # We got our clean and unpacked relation for each type\n",
    "    char_relations[c_type] = unpacked\n",
    "    \n",
    "    # Accumulate characters\n",
    "    all_characters = all_characters.append(unpacked[c_type], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>45.0</td>\n",
       "      <td>John Mishler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875358</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Maurice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875359</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Maurice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    characters\n",
       "39       45.0  John Mishler\n",
       "1875358  60.0       Maurice\n",
       "54       60.0           Max\n",
       "55       61.0           Max\n",
       "1875359  61.0       Maurice"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_relations['characters'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rawhide Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Max and Maurice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Brown Jones and Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Plish and Plum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Daral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      name\n",
       "1   1               Rawhide Kid\n",
       "2   2           Max and Maurice\n",
       "3   3  Brown Jones and Robinson\n",
       "4   4            Plish and Plum\n",
       "5   5                     Daral"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Characters table\n",
    "dataframes['characters'] = utils.extract_table(all_characters, 'name')\n",
    "dataframes['characters'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now replace values by IDs in the relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_type in char_types:\n",
    "    relation = char_relations[c_type]\n",
    "    relation.columns = ['story_id', 'character_id']\n",
    "    relation['character_id'] = utils.map_column(relation['character_id'], dataframes['characters'], 'id', 'name')\n",
    "    \n",
    "    if c_type == 'feature':\n",
    "        name = 'stories_features'\n",
    "    elif c_type == 'characters':\n",
    "        name = 'stories_characters'\n",
    "        \n",
    "    dataframes[name] = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>character_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>45.0</td>\n",
       "      <td>85178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875358</th>\n",
       "      <td>60.0</td>\n",
       "      <td>85179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>60.0</td>\n",
       "      <td>34106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>61.0</td>\n",
       "      <td>34106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875359</th>\n",
       "      <td>61.0</td>\n",
       "      <td>85179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         story_id  character_id\n",
       "39           45.0         85178\n",
       "1875358      60.0         85179\n",
       "54           60.0         34106\n",
       "55           61.0         34106\n",
       "1875359      61.0         85179"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['stories_characters'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>character_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    story_id  character_id\n",
       "0        6.0             1\n",
       "1        7.0             1\n",
       "2        8.0             1\n",
       "3        9.0             1\n",
       "54      60.0             2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['stories_features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now delete the features and the character columns from the story dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['story'] = dataframes['story'].drop(char_types, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editors table \n",
    "\n",
    "We are interested in creating a spearate table for all the editor of both the _Stories_ and the _Issues_. We will however create two relations, one for each table. There can be multiple editors per item we therfore need to unpack the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_editors = pd.Series()\n",
    "dfs = ['story','issue']\n",
    "editors_relations = {}\n",
    "\n",
    "for df in dfs:\n",
    "    # Extract relation and unpack the lists\n",
    "    unpacked = utils.unpack_column(dataframes[df][['id', 'editing']], 'id', 'editing')\n",
    "    \n",
    "    # Clean values\n",
    "    unpacked['editing'] = utils.clean_column(unpacked['editing'])\n",
    "    unpacked = unpacked.dropna(how='any')\n",
    "    \n",
    "    # We got our clean and unpacked relation for each type\n",
    "    editors_relations[df] = unpacked\n",
    "    \n",
    "    # Accumulate characters\n",
    "    all_editors = all_editors.append(unpacked['editing'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors_relations['story'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Editors table\n",
    "dataframes['editors'] = utils.extract_table(all_editors, 'name')\n",
    "dataframes['editors'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now map the editors relation table to the editor table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    relation = editors_relations[df]\n",
    "    relation.columns = [df+'_id', 'editor_id']\n",
    "    relation['editor_id'] = utils.map_column(relation['editor_id'], dataframes['editors'], 'id', 'name')\n",
    "    \n",
    "    if df == 'story':\n",
    "        name = 'stories_editing'\n",
    "    elif df == 'issue':\n",
    "        name = 'issues_editing'\n",
    "        \n",
    "    dataframes[name] = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['stories_editing'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['issues_editing'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now delete the editing column form both issue and story dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['story'] = dataframes['story'].drop('editing', axis=1)\n",
    "dataframes['issue'] = dataframes['issue'].drop('editing', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual files cleaning\n",
    "\n",
    "This part aims to clean each `.csv` file individually in order to remove dirty rows and clear values that need some special treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Country\n",
    "\n",
    "By browsing the country data, we see that one row is not valid, with ID 248. We see in the cell below that for `publisher`, for example, no row references this ID, which is with high probably pure dirty data, we can safely remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = dataframes['publisher']\n",
    "print('Number of publisher with country_id 248: {}.'.format(len(pub[pub['country_id'] == 248])))\n",
    "\n",
    "# Look for NaN values\n",
    "print('NaN values: ')\n",
    "df = dataframes['country']\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the desired row\n",
    "dataframes['country'] = df[df['id'] != 248]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story Reprint\n",
    "\n",
    "The story reprint table needs to be full, as we don't accept _NULL_ foreign keys in this case. We see in the cell below that there are no empty cells in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['story_reprint'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story Type\n",
    "\n",
    "By looking at the story types we see that the third row is problematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes['story_type']\n",
    "df.ix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if any story contains a reference to this row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = dataframes['story']\n",
    "print('Number of stories referencing ID 3: {}.'.format(len(stories[stories['type_id'] == 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes['story_type'] = df[df['id'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language\n",
    "\n",
    "Looking at the language file, all the rows are clean and it's safe to keep them as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes['language'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brang group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes['brand_group'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the essential attributes don't have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes['brand_group']['name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we see that there are quite a lot of duplicates in the names. But if we look at the cell below, for the same names, we have each time different *publisher_id*s, so it makes sense to keep these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['brand_group'][dataframes['brand_group']['name'] == 'Marvel']['publisher_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Publication types\n",
    "Obviously this table is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes['series_publication_type'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Reprint\n",
    "\n",
    "We make sure there is no null rows in the reprint table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframes['issue_reprint'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicia Publisher\n",
    "\n",
    "For this table we need to make sure the *publisher_id* attribute is not null, which is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframes['indicia_publisher'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that every publisher as a name, which is the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['publisher'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did some cleaning at the beginning for cells that contained no information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files\n",
    "\n",
    "We can now save our clean and new tables, ready for database loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join('..', 'data', 'clean')\n",
    "\n",
    "#for name, df in dataframes.items():\n",
    "#    df.to_csv(name.title() + '.csv', index=False, float_format='%.0f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we collect the max and average length of string attributes for each column of each table, in order to help use choosing right string lengths for the databas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = {}\n",
    "for name, df in dataframes.items():\n",
    "    tmp = {}\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if (col_type == np.dtype('O') and type(df[col].dropna().iloc[0]) == str) or col_type == np.dtype(str):\n",
    "            strs = df[col].dropna().str.len()\n",
    "            tmp[col] = {'min': int(min(strs)),\n",
    "                        'max': int(max(strs)),\n",
    "                        'ave': int(sum(strs) / len(strs))}\n",
    "    if len(tmp) > 0:        \n",
    "        lengths[name] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_PATH, 'lengths.json'), 'w') as file:\n",
    "    json.dump([lengths], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
